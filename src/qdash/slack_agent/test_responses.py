#!/usr/bin/env python3.10
"""
Test improved Japanese responses.
"""

import asyncio
import logging
import os
from qdash.config import get_settings
from qdash.slack_agent.config_manager import get_current_model_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_improved_responses():
    """Test improved Japanese responses."""
    try:
        from strands import Agent, tool
        from strands.models.openai import OpenAIModel
        
        # Get model configuration
        model_config = get_current_model_config()
        settings = get_settings()
        
        # Get API key
        api_key = (getattr(settings, 'openai_api_key', None) or 
                  model_config.api_key or 
                  os.getenv("OPENAI_API_KEY"))
        
        if not api_key:
            logger.error("âŒ No OpenAI API key available")
            return False
        
        # System prompt (improved)
        system_prompt = f"""ã‚ãªãŸã¯QDashé‡å­ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®Slackã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

åŸºæœ¬çš„ãªå¯¾å¿œ:
- æ—¥æœ¬èªã§è‡ªç„¶ã«è¿”ç­”ã—ã¦ãã ã•ã„
- ç°¡æ½”ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ç­”ãˆã¦ãã ã•ã„
- æŒ¨æ‹¶ã«ã¯æ™®é€šã«æŒ¨æ‹¶ã§è¿”ã—ã¦ãã ã•ã„

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
- get_current_time: ç¾åœ¨æ™‚åˆ»å–å¾—
- calculate: æ•°å¼è¨ˆç®—

ä½¿ç”¨æ–¹é‡:
- å˜ç´”ãªæŒ¨æ‹¶ã‚„é›‘è«‡ã«ã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã‚ãšè‡ªç„¶ã«è¿”ç­”ã—ã¦ãã ã•ã„

Model: {model_config.name}
"""
        
        # Create simple tools
        @tool
        async def get_current_time() -> str:
            """Get current time in JST timezone."""
            from datetime import datetime, timezone, timedelta
            jst = timezone(timedelta(hours=9))
            return datetime.now(tz=jst).strftime("%Y-%m-%d %H:%M:%S JST")
        
        @tool
        async def calculate(expression: str) -> float:
            """Calculate mathematical expression safely."""
            import ast
            import operator
            
            try:
                # Simple safe evaluation
                node = ast.parse(expression, mode='eval')
                return eval(compile(node, '<string>', 'eval'))
            except:
                return "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
        
        # Create model configuration
        model_params = {
            "temperature": 0.3,  # Slightly higher for more natural responses
            "max_completion_tokens": 2000,
        }
        
        model = OpenAIModel(
            client_args={"api_key": api_key},
            model_id=model_config.name,
            params=model_params
        )
        
        # Create agent
        agent = Agent(
            model=model,
            system_prompt=system_prompt,
            tools=[get_current_time, calculate]
        )
        
        # Test various inputs
        test_cases = [
            "ã“ã‚“ã«ã¡ã¯",
            "ãŠã¯ã‚ˆã†ï¼",
            "ä»Šä½•æ™‚ã§ã™ã‹ï¼Ÿ",
            "2+3ã¯ã„ãã¤ï¼Ÿ",
            "èª¿å­ã¯ã©ã†ï¼Ÿ"
        ]
        
        logger.info("Testing improved responses:")
        for test_input in test_cases:
            logger.info(f"\nå…¥åŠ›: {test_input}")
            result = await agent.invoke_async(test_input)
            response = str(result)
            logger.info(f"å¿œç­”: {response}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Response test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Run response tests."""
    logger.info("ğŸ§ª Testing Improved Japanese Responses")
    
    success = await test_improved_responses()
    
    if success:
        logger.info("ğŸ‰ Response tests completed!")
    else:
        logger.error("âŒ Response tests failed")
        
    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)